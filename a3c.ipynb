{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from pylab import *\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ACTIONS = 9\n",
    "actions = np.arange(N_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'at' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-143913ca34fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m                 activation=None)\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_softmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr_op\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#t = tf.train.AdamOptimizer().minimize(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'at' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "s_op = tf.placeholder(tf.float32, [None, 84, 84, 4])\n",
    "r_op = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "p = {}\n",
    "pi = {}\n",
    "\n",
    "for scope in ['network1', 'network2']:\n",
    "    with tf.variable_scope(scope):\n",
    "        x = tf.layers.conv2d(\n",
    "                inputs=s_op,\n",
    "                filters=32,\n",
    "                kernel_size=8,\n",
    "                strides=4,\n",
    "                activation=tf.nn.relu)\n",
    "\n",
    "        x = tf.layers.conv2d(\n",
    "                inputs=x,\n",
    "                filters=64,\n",
    "                kernel_size=4,\n",
    "                strides=2,\n",
    "                activation=tf.nn.relu)\n",
    "\n",
    "        x = tf.layers.conv2d(\n",
    "                inputs=x,\n",
    "                filters=64,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                activation=tf.nn.relu)\n",
    "\n",
    "        w, h, f = x.shape[1:]\n",
    "        x = tf.reshape(x, [-1, int(w * h * f)])\n",
    "\n",
    "        x = tf.layers.dense(\n",
    "                inputs=x,\n",
    "                units=512,\n",
    "                activation=tf.nn.relu)\n",
    "\n",
    "        a_logits = tf.layers.dense(\n",
    "                inputs=x,\n",
    "                units=N_ACTIONS,\n",
    "                activation=None)\n",
    "\n",
    "        if scope == 'network1':\n",
    "            a_softmax = tf.nn.softmax(a_logits)\n",
    "            a_max = tf.reduce_max(a_softmax, axis=1)\n",
    "        else:\n",
    "            v = tf.layers.dense(\n",
    "                inputs=x,\n",
    "                units=1,\n",
    "                activation=None)\n",
    "\n",
    "#lp = tf.log(a_softmax[at]) * (r_op - v)\n",
    "                              \n",
    "#t = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = tf.losses.log_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_network():\n",
    "    n1_dict = {var.name: var for var in tf.trainable_variables() if 'network1' in var.name}\n",
    "    n2_dict = {var.name: var for var in tf.trainable_variables() if 'network2' in var.name}\n",
    "    copy_ops = []\n",
    "    for name, var in n2_dict.items():\n",
    "        op = var.assign(n1_dict[name.replace('network2', 'network1')].value())\n",
    "        copy_ops.append(op)\n",
    "    sess.run(copy_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def with_prob(p):\n",
    "    if np.random.random() < p:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "epsilon = 0.1\n",
    "g = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEnv:\n",
    "    \n",
    "    action_space = gym.spaces.discrete.Discrete(2)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.i = 0\n",
    "        self.reward = 0\n",
    "        return np.zeros(shape=(84, 84, 4))\n",
    "    def step(self, a):\n",
    "        if self.i == 5:\n",
    "            done = True\n",
    "            reward = self.reward\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 0\n",
    "            self.reward += a\n",
    "            self.i += 1\n",
    "        return np.zeros(shape=(84, 84, 4)), reward, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-13 19:28:53,748] Making new env: Enduro-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Enduro-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took action 1\n",
      "Got reward  0\n",
      "Took action 1\n",
      "Got reward  0\n",
      "Took action 0\n",
      "Got reward  0\n",
      "Took action 0\n",
      "Got reward  0\n",
      "Took action 1\n",
      "Got reward  0\n",
      "Took action 0\n",
      "Got reward  3\n"
     ]
    }
   ],
   "source": [
    "env = DummyEnv()\n",
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    a = env.action_space.sample()\n",
    "    print(\"Took action\", a)\n",
    "    _, reward, done, _ = env.step(a)\n",
    "    print(\"Got reward \", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "t_max = 100\n",
    "\n",
    "s = np.zeros(10)\n",
    "r1 = np.zeros(10)\n",
    "a = np.zeros(10)\n",
    "r2_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    t_start = t\n",
    "    s[t] = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while True:\n",
    "        a_p = sess.run(ap_op, feed_dict={s_op: s})\n",
    "        a[t] = np.random.choice(ACTIONS, p=a_p)\n",
    "        s[t+1], r[t], done, _ = env.step(a[t])\n",
    "        t += 1        \n",
    "    if done or t - t_start == t_max:\n",
    "        break\n",
    "    \n",
    "    if done:\n",
    "        r2 = 0\n",
    "    else:\n",
    "        r2 = sess.run(v_op, feed_dict={s_op: s[t]})\n",
    "    \n",
    "    for i in range(t-1, t_start-1, -1):\n",
    "        r2_list.append(r[i] + g * r2)\n",
    "    \n",
    "    \n",
    "    sess.run(t1, feed_dict={s_op: s, big_r_op: r})\n",
    "    sess.run(t2, feed_dict={s_op: s, big_r_op: r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation.shape\n",
    "action = env.action_space.sample()\n",
    "os = []\n",
    "for i in range(4):\n",
    "    o1, _, _, _ = env.step(action)\n",
    "    o2, _, _, _ = env.step(action)\n",
    "    o = np.maximum(o1, o2)\n",
    "    o = np.mean(o, axis=2)\n",
    "    o = scipy.misc.imresize(o, (84, 84))\n",
    "    os.append(o)\n",
    "os = np.stack(os, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 84, 84, 4)\n",
      "[[  0.69894785  -0.22462213   5.59576368  -7.67884588  16.15483665\n",
      "    2.82746601   0.95167667   5.31193829   0.30126441]]\n",
      "[ 16.15483665]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "os = np.resize(os, (1, 84, 84, 4))\n",
    "print(os.shape)\n",
    "print(sess.run(q['network1'], feed_dict={s: os}))\n",
    "print(sess.run(qi['network1'], feed_dict={s: os}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
