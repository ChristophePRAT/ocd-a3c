{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = tf.placeholder(tf.int64, shape=[3])\n",
    "p = tf.placeholder(tf.int64, shape=[3])\n",
    "ll = tf.losses.log_loss(labels=l, predictions=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(ll, feed_dict={l: [1, 2, 3], p: [1, 2, 3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy.random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10181 0.09952 0.79867\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "p = [0.1, 0.1, 0.8]\n",
    "r = np.random.choice(a, size=100000, p=p)\n",
    "s1 = np.sum(r == 1)\n",
    "s2 = np.sum(r == 2)\n",
    "s3 = np.sum(r == 3)\n",
    "d = s1 + s2 + s3\n",
    "print(s1/d, s2/d, s3/d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_scope/a:0\n",
      "test_scope/b:0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope('test_scope'):\n",
    "    a = tf.Variable(tf.ones(shape=(2, 2)), name='a')\n",
    "    b = 2 * tf.Variable(tf.ones(shape=(2, 2)), name='b')\n",
    "loss = tf.reduce_sum(a + b, name='loss')\n",
    "\n",
    "for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='test_scope'):\n",
    "    print(v.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'b:0' shape=(2, 2) dtype=float32_ref> Tensor(\"gradients/mul_grad/tuple/control_dependency_1:0\", shape=(2, 2), dtype=float32)\n",
      "<tf.Variable 'a:0' shape=(2, 2) dtype=float32_ref> Tensor(\"gradients/add_grad/tuple/control_dependency:0\", shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "o = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "grads_and_vars = o.compute_gradients(loss, tf.trainable_variables())\n",
    "grads_dict = {var: grads for grads, var in grads_and_vars}\n",
    "for var, grads in grads_dict.items():\n",
    "    print(var, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_bufs = {}\n",
    "for var, grads in grads_dict.items():\n",
    "    grad_bufs[var] = \\\n",
    "        tf.Variable(tf.zeros(shape=grads.shape), trainable=False)\n",
    "        \n",
    "update_ops = []\n",
    "for var in grads_dict.keys():\n",
    "    assign = grad_bufs[var]\n",
    "    add = grads_dict[var]\n",
    "    update_ops.append(tf.assign_add(assign, add))\n",
    "update_gradients = tf.group(*update_ops)\n",
    "    \n",
    "grad_bufs_and_vars = []\n",
    "for var, grad_buf in grad_bufs.items():\n",
    "    grad_bufs_and_vars.append((grad_buf, var))\n",
    "\n",
    "apply_gradients = o.apply_gradients(grad_bufs_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.,  1.],\n",
      "       [ 1.,  1.]], dtype=float32)]\n",
      "[array([[ 2.,  2.],\n",
      "       [ 2.,  2.]], dtype=float32)]\n",
      "\n",
      "[array([[ 1.,  1.],\n",
      "       [ 1.,  1.]], dtype=float32)]\n",
      "[array([[ 2.,  2.],\n",
      "       [ 2.,  2.]], dtype=float32)]\n",
      "\n",
      "[array([[ 0.89999998,  0.89999998],\n",
      "       [ 0.89999998,  0.89999998]], dtype=float32)]\n",
      "[array([[ 1.60000002,  1.60000002],\n",
      "       [ 1.60000002,  1.60000002]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run([a])); print(sess.run([b])); print()\n",
    "sess.run(update_gradients)\n",
    "print(sess.run([a])); print(sess.run([b])); print()\n",
    "sess.run(apply_gradients)\n",
    "print(sess.run([a])); print(sess.run([b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.,  1.],\n",
      "       [ 1.,  1.]], dtype=float32)]\n",
      "[array([[ 2.,  2.],\n",
      "       [ 2.,  2.]], dtype=float32)]\n",
      "\n",
      "[array([[ 1.,  1.],\n",
      "       [ 1.,  1.]], dtype=float32)]\n",
      "[array([[ 2.,  2.],\n",
      "       [ 2.,  2.]], dtype=float32)]\n",
      "\n",
      "[array([[ 0.80000001,  0.80000001],\n",
      "       [ 0.80000001,  0.80000001]], dtype=float32)]\n",
      "[array([[ 1.20000005,  1.20000005],\n",
      "       [ 1.20000005,  1.20000005]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run([a])); print(sess.run([b])); print()\n",
    "sess.run(update_gradients)\n",
    "sess.run(update_gradients)\n",
    "print(sess.run([a])); print(sess.run([b])); print()\n",
    "sess.run(apply_gradients)\n",
    "print(sess.run([a])); print(sess.run([b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreaded TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "In f!\n"
     ]
    }
   ],
   "source": [
    "def f(sess, var):\n",
    "    print(\"In f!\")\n",
    "    print(sess.run(var))\n",
    "    print(\"Done!\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "w1 = tf.Variable(5)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(w1))\n",
    "\n",
    "p1 = Process(target=f, args=(sess, w1))\n",
    "p1.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task: a process, running in a node in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_ps_graph():\n",
    "    with tf.device(\"/job:ps/task:0\"):\n",
    "        w = tf.Variable(0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_worker_graph(w):\n",
    "    with tf.device(\"/job:ps/task:0\"):\n",
    "        add = tf.assign_add(w, 1)\n",
    "    return add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = tf.train.ClusterSpec({\"worker\": [\"localhost:2222\"],\n",
    "                                \"ps\":     [\"localhost:2223\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps():\n",
    "    # Describes list of \"tasks\" (i.e. list of processes)\n",
    "    # Should be the same for all tasks (i.e. all processes)\n",
    "    # Create a \"server\",\n",
    "    # and register the current \"task\" (i.e. the current process)\n",
    "    # on the cluster\n",
    "    server = tf.train.Server(cluster, job_name=\"ps\")\n",
    "    w = create_ps_graph()\n",
    "    sess = tf.Session(server.target)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Joining...\")\n",
    "    server.join()\n",
    "\n",
    "def worker():\n",
    "    server = tf.train.Server(cluster, job_name=\"worker\")\n",
    "    w = create_ps_graph()\n",
    "    add = create_worker_graph(w)\n",
    "    sess = tf.Session(server.target)\n",
    "    while len(sess.run(tf.report_uninitialized_variables())) > 0:\n",
    "        print(\"Sleeping...\")\n",
    "    print(sess.run(add))\n",
    "    \n",
    "def worker2():\n",
    "    server = tf.train.Server(cluster, job_name=\"worker\")\n",
    "    w = create_ps_graph()\n",
    "    add = create_worker_graph(w)\n",
    "    sess = tf.Session(server.target)\n",
    "    while len(sess.run(tf.report_uninitialized_variables())) > 0:\n",
    "        print(\"Sleeping...\")\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps_p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining...\n"
     ]
    }
   ],
   "source": [
    "ps_p = Process(target=ps)\n",
    "ps_p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worker_p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "worker_p = Process(target=worker)\n",
    "worker_p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "worker_p_2 = Process(target=worker2)\n",
    "worker_p_2.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
